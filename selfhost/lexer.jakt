// Copyright (c) 2022, JT <jt@serenityos.org>
// Copyright (c) 2022, Andreas Kling <kling@serenityos.org>
//
// SPDX-License-Identifier: BSD-2-Clause

import error { JaktError }
import utility { Span }

// FIXME: These should not need explicit "-> bool" return types.
function is_ascii_alpha(anon c: u8) -> bool => (c >= b'a' and c <= b'z') or (c >= b'A' and c <= b'Z')
function is_ascii_digit(anon c: u8) -> bool => (c >= b'0' and c <= b'9')
function is_ascii_hexdigit(anon c: u8) -> bool => (c >= b'0' and c <= b'9') or (c >= b'a' and c <= b'f') or (c >= b'A' and c <= b'F')
function is_ascii_alphanumeric(anon c: u8) -> bool => is_ascii_alpha(c) or is_ascii_digit(c)

enum LiteralSuffix {
    UZ,
    U8,
    U16,
    U32,
    U64,
    I8,
    I16,
    I32,
    I64,
    F32,
    F64
}

enum Token {
    SingleQuotedString(quote: String, span: Span)
    SingleQuotedByteString(quote: String, span: Span)
    QuotedString(quote: String, span: Span)
    Number(number: i64, literal_suffix: LiteralSuffix?, span: Span)
    Identifier(name: String, span: Span)
    Semicolon(Span)
    Colon(Span)
    ColonColon(Span)
    LParen(Span)
    RParen(Span)
    LCurly(Span)
    RCurly(Span)
    LSquare(Span)
    RSquare(Span)
    PercentSign(Span)
    Plus(Span)
    Minus(Span)
    Equal(Span)
    PlusEqual(Span)
    PlusPlus(Span)
    MinusEqual(Span)
    MinusMinus(Span)
    AsteriskEqual(Span)
    ForwardSlashEqual(Span)
    PercentSignEqual(Span)
    NotEqual(Span)
    DoubleEqual(Span)
    GreaterThan(Span)
    GreaterThanOrEqual(Span)
    LessThan(Span)
    LessThanOrEqual(Span)
    LeftArithmeticShift(Span)
    LeftShift(Span)
    LeftShiftEqual(Span)
    RightShift(Span)
    RightArithmeticShift(Span)
    RightShiftEqual(Span)
    Asterisk(Span)
    Ampersand(Span)
    AmpersandEqual(Span)
    Pipe(Span)
    PipeEqual(Span)
    Caret(Span)
    CaretEqual(Span)
    Dollar(Span)
    Tilde(Span)
    ForwardSlash(Span)
    ExclamationPoint(Span)
    QuestionMark(Span)
    QuestionMarkQuestionMark(Span)
    QuestionMarkQuestionMarkEqual(Span)
    Comma(Span)
    Dot(Span)
    DotDot(Span)
    Eol(Span)
    Eof(Span)
    FatArrow(Span)
    Arrow(Span)

    // Keywords
    And(Span)
    Anon(Span)
    As(Span)
    Boxed(Span)
    Break(Span)
    Catch(Span)
    Class(Span)
    Continue(Span)
    Cpp(Span)
    Defer(Span)
    Else(Span)
    Enum(Span)
    Extern(Span)
    False(Span)
    For(Span)
    Function(Span)
    If(Span)
    Import(Span)
    In(Span)
    Is(Span)
    Let(Span)
    Loop(Span)
    Match(Span)
    Mut(Span)
    Namespace(Span)
    Not(Span)
    Or(Span)
    Private(Span)
    Public(Span)
    Raw(Span)
    Return(Span)
    Restricted(Span)
    Struct(Span)
    This(Span)
    Throw(Span)
    Throws(Span)
    True(Span)
    Try(Span)
    Unsafe(Span)
    Weak(Span)
    While(Span)
    Yield(Span)

    // Catch-all for failed parses
    Garbage(Span)

    public function span(this) => match this {
        SingleQuotedString(quote, span) => span
        SingleQuotedByteString(quote, span) => span
        QuotedString(quote, span) => span
        Number(number, span) => span
        Identifier(name, span) => span
        Semicolon(span) => span
        Colon(span) => span
        ColonColon(span) => span
        Cpp(span) => span
        LParen(span) => span
        RParen(span) => span
        LCurly(span) => span
        RCurly(span) => span
        LSquare(span) => span
        RSquare(span) => span
        PercentSign(span) => span
        Plus(span) => span
        Minus(span) => span
        Equal(span) => span
        PlusEqual(span) => span
        PlusPlus(span) => span
        MinusEqual(span) => span
        MinusMinus(span) => span
        Arrow(span) => span
        AsteriskEqual(span) => span
        ForwardSlashEqual(span) => span
        PercentSignEqual(span) => span
        NotEqual(span) => span
        DoubleEqual(span) => span
        GreaterThan(span) => span
        GreaterThanOrEqual(span) => span
        LessThan(span) => span
        LessThanOrEqual(span) => span
        LeftArithmeticShift(span) => span
        LeftShift(span) => span
        LeftShiftEqual(span) => span
        RightShift(span) => span
        RightArithmeticShift(span) => span
        RightShiftEqual(span) => span
        Asterisk(span) => span
        Ampersand(span) => span
        AmpersandEqual(span) => span
        Pipe(span) => span
        PipeEqual(span) => span
        Caret(span) => span
        CaretEqual(span) => span
        Dollar(span) => span
        Tilde(span) => span
        ForwardSlash(span) => span
        ExclamationPoint(span) => span
        QuestionMark(span) => span
        QuestionMarkQuestionMark(span) => span
        QuestionMarkQuestionMarkEqual(span) => span
        Comma(span) => span
        Dot(span) => span
        DotDot(span) => span
        Eol(span) => span
        Eof(span) => span
        FatArrow(span) => span
        And(span) => span
        Anon(span) => span
        As(span) => span
        Boxed(span) => span
        Break(span) => span
        Catch(span) => span
        Class(span) => span
        Continue(span) => span
        Defer(span) => span
        Else(span) => span
        Enum(span) => span
        Extern(span) => span
        False(span) => span
        For(span) => span
        Function(span) => span
        If(span) => span
        Import(span) => span
        In(span) => span
        Is(span) => span
        Let(span) => span
        Loop(span) => span
        Match(span) => span
        Mut(span) => span
        Namespace(span) => span
        Not(span) => span
        Or(span) => span
        Private(span) => span
        Public(span) => span
        Raw(span) => span
        Restricted(span) => span
        Return(span) => span
        Struct(span) => span
        This(span) => span
        Throw(span) => span
        Throws(span) => span
        True(span) => span
        Try(span) => span
        Unsafe(span) => span
        Weak(span) => span
        While(span) => span
        Yield(span) => span
        Garbage(span) => span
    }

    function from_keyword_or_identifier(string: String, span: Span) => match string {
        "and" => Token::And(span)
        "anon" => Token::Anon(span)
        "as" => Token::As(span)
        "boxed" => Token::Boxed(span)
        "break" => Token::Break(span)
        "catch" => Token::Catch(span)
        "class" => Token::Class(span)
        "continue" => Token::Continue(span)
        "cpp" => Token::Cpp(span)
        "defer" => Token::Defer(span)
        "else" => Token::Else(span)
        "enum" => Token::Enum(span)
        "extern" => Token::Extern(span)
        "false" => Token::False(span)
        "for" => Token::For(span)
        "function" => Token::Function(span)
        "if" => Token::If(span)
        "import" => Token::Import(span)
        "in" => Token::In(span)
        "is" => Token::Is(span)
        "let" => Token::Let(span)
        "loop" => Token::Loop(span)
        "match" => Token::Match(span)
        "mut" => Token::Mut(span)
        "namespace" => Token::Namespace(span)
        "not" => Token::Not(span)
        "or" => Token::Or(span)
        "private" => Token::Private(span)
        "public" => Token::Public(span)
        "raw" => Token::Raw(span)
        "return" => Token::Return(span)
        "restricted" => Token::Restricted(span)
        "struct" => Token::Struct(span)
        "this" => Token::This(span)
        "throw" => Token::Throw(span)
        "throws" => Token::Throws(span)
        "true" => Token::True(span)
        "try" => Token::Try(span)
        "unsafe" => Token::Unsafe(span)
        "weak" => Token::Weak(span)
        "while" => Token::While(span)
        "yield" => Token::Yield(span)
        else => Token::Identifier(name: string, span)
    }
}

// Can't return tuples from function. Thus created this intermediate struct.
struct ReadIntegerResult {
    // Integer parsed if found
    public integer: i64
    // New index to start lex if used.
    public new_index: usize 
}

struct Lexer {
    index: usize
    input: [u8]
    errors: [JaktError]

    function lex(input: [u8], errors: [JaktError]) throws -> [Token] {
        mut lexer = Lexer(index: 0, input, errors)
        mut tokens: [Token] = []

        for token in lexer {
            tokens.push(token)
        }

        return tokens
    }

    function error(mut this, anon message: String, anon span: Span) throws {
        .errors.push(JaktError::Message(message, span))
    }

    // Peek at next upcoming character
    function peek(this) -> u8 {
        println("input length: {}, index: {}", .input.size(), .index)
        if .eof() {
            return 0
        }
        return .input[.index]
    }

    // Peek at upcoming characters, N steps ahead in the stream
    // FIXME: This could be merged with peek() once we support default arguments
    function peek_ahead(this, anon steps: usize) -> u8 {
        if .index + steps >= .input.size() {
            return 0
        }
        return .input[.index + steps]
    }

    function eof(this) -> bool {
        return .index >= .input.size()
    }

    function substring(this, start: usize, length: usize) throws -> String {
        mut builder = StringBuilder::create()
        for i in start..length {
            builder.append(.input[i])
        }
        return builder.to_string()
    }

    function lex_character_constant_or_name(mut this) throws -> Token {
        if .peek_ahead(1) != b'\'' {
            return .lex_number_or_name()
        }

        let is_byte = .peek() == b'b'
        if is_byte {
            .index++
        }

        let start = .index
        .index++

        mut escaped = false;

        while not .eof() and (escaped or .peek() != b'\'') {
            if not escaped and .peek() == b'\\' {
                escaped = true
            } else {
                escaped = false
            }

            .index++
        }

        if .eof() or .peek() != b'\'' {
            .error("expected single quote", Span(start, end: start))
        }

        // Everything but the quotes
        mut builder = StringBuilder::create()
        builder.append(.input[start + 1])
        let str = builder.to_string()

        .index++

        let end = .index

        if is_byte {
            return Token::SingleQuotedByteString(quote: str, span: Span(start, end))
        }
        return Token::SingleQuotedString(quote: str, span: Span(start, end))
    }

    function read_ascii_integer(mut this, mut start_index: usize) -> ReadIntegerResult? {
        println("read_ascii_integer")

        mut local_index = start_index

        mut total: i64 = 0

        if (.eof()) {
            return None
        }

        while (not .eof()) and is_ascii_digit(.input[local_index]) {
            let value = .input[local_index]
            local_index += 1
            let digit: i64 = as_saturated(value - b'0')
            total = total * 10 + digit
        }

        if (local_index != start_index) {
            println("exit read_ascii_integer")
            return ReadIntegerResult(integer: total, new_index: local_index)
        } else {
            println("exit read_ascii_integer")
            return None
        }
    }

    function read_literal_suffix(mut this) -> LiteralSuffix? {
        println("read_literal_suffix")

        let number_width_result = .read_ascii_integer(start_index: .index + 1)
        if (not number_width_result.has_value()) {
            return None
        }

        let number_width = number_width_result.value().integer
        let new_index = number_width_result.value().new_index

        // Doing this ugly thing because yield doesn't work with optional enums
        mut result: LiteralSuffix? = None
        let suffix_letter = .peek()
        match suffix_letter {
            b'u' => {
                match number_width {
                    8 => { result = LiteralSuffix::U8 }
                    16 => { result = LiteralSuffix::U16 }
                    32 => { result = LiteralSuffix::U32 }
                    64 => { result = LiteralSuffix::U64 }
                    else => {}
                }
            }
            b'i' => {
                match number_width {
                    8 => { result = LiteralSuffix::I8 }
                    16 => { result = LiteralSuffix::I16 }
                    32 => { result = LiteralSuffix::I32 }
                    64 => { result = LiteralSuffix::I64 }
                    else => {}
                }
            }
            b'f' => {
                match number_width {
                    32 => { result = LiteralSuffix::F32 }
                    64 => { result = LiteralSuffix::F64 }
                    else => {}
                }
            }
            else => { return None }
        }
        
        if (result.has_value()) {
            .index = new_index
        }
        
        return result
    }

    function lex_number_or_name(mut this) throws -> Token {

        let start = .index

        if .eof() {
            .error("unexpected eof", Span(start, end: start))
            return Token::Garbage(Span(start, end: start))
        }

        let ascii_number_result = .read_ascii_integer(start_index: .index)

        if ascii_number_result.has_value() {
            let ascii_number = ascii_number_result.value().integer
            // If a valid number, advance the index.
            .index = ascii_number_result.value().new_index
            let number = ascii_number
            let end = .index
                
            // For now this is ignored
            let literal_suffix = .read_literal_suffix()

            return Token::Number(number, literal_suffix, span: Span(start, end))
        } else if is_ascii_alpha(.peek()) or .peek() == b'_' {
            mut string_builder = StringBuilder::create()

            while is_ascii_alphanumeric(.peek()) or .peek() == b'_' {
                let value = .input[.index]
                ++.index
                string_builder.append(value)
            }
            let end = .index
            let span = Span(start, end)
            let string = string_builder.to_string()

            return Token::from_keyword_or_identifier(string, span)
        }

        let unknown_char = .input[.index]
        let end = ++.index
        .error(format("unknown character: {:c}", unknown_char), Span(start, end))
        return Token::Garbage(Span(start, end))
    }

    function lex_quoted_string(mut this, delimiter: u8) throws -> Token {
        let start = .index

        ++.index

        if .eof() {
            .error("unexpected eof", Span(start, end: start))
            return Token::Garbage(Span(start, end: start))
        }

        mut escaped = false
        while not .eof() and (escaped or .peek() != delimiter) {
            if not escaped and .peek() == b'\\' {
                escaped = true
            } else {
                escaped = false
            }
            ++.index
        }

        let end = .index

        let str = .substring(start: start + 1, length: .index)

        .index++

        if delimiter == b'\'' {
            return Token::SingleQuotedString(quote: str, span: Span(start, end))
        }

        return Token::QuotedString(quote: str, span: Span(start, end))
    }

    function lex_plus(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::PlusEqual(Span(start, end: ++.index))
            b'+' => Token::PlusPlus(Span(start, end: ++.index))
            else => Token::Plus(Span(start: .index - 1, end: .index))
        }
    }

    function lex_minus(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::MinusEqual(Span(start, end: ++.index))
            b'-' => Token::MinusMinus(Span(start, end: ++.index))
            b'>' => Token::Arrow(Span(start, end: ++.index))
            else => Token::Minus(Span(start: .index - 1, end: .index))
        }
    }

    function lex_asterisk(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::AsteriskEqual(Span(start, end: ++.index))
            else => Token::Asterisk(Span(start: .index - 1, end: .index))
        }
    }

    function lex_forward_slash(mut this) throws -> Token {
        let start = .index++
        if .peek() == b'=' {
            return Token::ForwardSlashEqual(Span(start, end: ++.index))
        }
        if .peek() != b'/' {
            return Token::ForwardSlash(Span(start, end: .index))
        }
        // We're in a comment, swallow to end of line.
        while not .eof() {
            let c = .peek()
            .index++
            if c == b'\n' {
                break
            }
        }
        return .next() ?? Token::Eof(Span(start: .index, end: .index))
    }

    function lex_caret(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::CaretEqual(Span(start, end: ++.index))
            else => Token::Caret(Span(start: .index - 1, end: .index))
        }
    }

    function lex_pipe(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::PipeEqual(Span(start, end: ++.index))
            else => Token::Pipe(Span(start: .index - 1, end: .index))
        }
    }

    function lex_percent_sign(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::PercentSignEqual(Span(start, end: ++.index))
            else => Token::PercentSign(Span(start: .index - 1, end: .index))
        }
    }

    function lex_exclamation_point(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::NotEqual(Span(start, end: ++.index))
            else => Token::ExclamationPoint(Span(start: .index - 1, end: .index))
        }
    }

    function lex_ampersand(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::AmpersandEqual(Span(start, end: ++.index))
            else => Token::Ampersand(Span(start: .index - 1, end: .index))
        }
    }

    function lex_less_than(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::LessThanOrEqual(Span(start, end: ++.index))
            b'<' => Token::LeftShift(Span(start, end: ++.index))
            else => Token::LessThan(Span(start: .index - 1, end: .index))
        }
    }

    function lex_greater_than(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::GreaterThanOrEqual(Span(start, end: ++.index))
            b'>' => Token::RightShift(Span(start, end: ++.index))
            else => Token::GreaterThan(Span(start: .index - 1, end: .index))
        }
    }

    function lex_dot(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'.' => Token::DotDot(Span(start, end: ++.index))
            else => Token::Dot(Span(start: .index - 1, end: .index))
        }
    }

    function lex_colon(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b':' => Token::ColonColon(Span(start, end: ++.index))
            else => Token::Colon(Span(start: .index - 1, end: .index))
        }
    }

    function lex_question_mark(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'?' => {
                .index++
                yield match .peek() {
                    b'=' => Token::QuestionMarkQuestionMarkEqual(Span(start, end: ++.index))
                    else => Token::QuestionMarkQuestionMark(Span(start, end: .index))
                }
            }
            else => Token::QuestionMark(Span(start: .index - 1, end: .index))
        }
    }

    function lex_equals(mut this) -> Token {
        let start = .index++
        return match .peek() {
            b'=' => Token::DoubleEqual(Span(start, end: ++.index))
            b'>' => Token::FatArrow(Span(start, end: ++.index))
            else => Token::Equal(Span(start: .index - 1, end: .index))
        }
    }

    function next(mut this) throws -> Token? {
        if .index == .input.size() {
            ++.index
            return Token::Eof(Span(start: .index - 1, end: .index - 1))
        }
        if .eof() {
            return None
        }
        loop {
            let ch = .peek()
            if ch == b' ' or ch == b'\t' or ch == b'\r' {
                .index++
            } else {
                break
            }
        }

        let start = .index

        return match .input[.index] {
            b'(' => Token::LParen(Span(start, end: ++.index))
            b')' => Token::RParen(Span(start, end: ++.index))
            b'[' => Token::LSquare(Span(start, end: ++.index))
            b']' => Token::RSquare(Span(start, end: ++.index))
            b'{' => Token::LCurly(Span(start, end: ++.index))
            b'}' => Token::RCurly(Span(start, end: ++.index))
            b'<' => .lex_less_than()
            b'>' => .lex_greater_than()
            b'.' => .lex_dot()
            b',' => Token::Comma(Span(start, end: ++.index))
            b'~' => Token::Tilde(Span(start, end: ++.index))
            b';' => Token::Semicolon(Span(start, end: ++.index))
            b':' => .lex_colon()
            b'?' => .lex_question_mark()
            b'+' => .lex_plus()
            b'-' => .lex_minus()
            b'*' => .lex_asterisk()
            b'/' => .lex_forward_slash()
            b'^' => .lex_caret()
            b'|' => .lex_pipe()
            b'%' => .lex_percent_sign()
            b'!' => .lex_exclamation_point()
            b'&' => .lex_ampersand()
            b'$' => Token::Dollar(Span(start, end: ++.index))
            b'=' => .lex_equals()
            b'\n' => Token::Eol(Span(start, end: ++.index))
            b'\'' => .lex_quoted_string(delimiter: b'\'')
            b'\"' => .lex_quoted_string(delimiter: b'"')
            b'b' => .lex_character_constant_or_name()
            b'c' => .lex_character_constant_or_name()
            else => .lex_number_or_name()
        }
    }
}
